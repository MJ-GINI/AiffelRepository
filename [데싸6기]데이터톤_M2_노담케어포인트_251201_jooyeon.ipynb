{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MJ-GINI/AiffelRepository/blob/main/%5B%E1%84%83%E1%85%A6%E1%84%8A%E1%85%A16%E1%84%80%E1%85%B5%5D%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%90%E1%85%A9%E1%86%AB_M2_%E1%84%82%E1%85%A9%E1%84%83%E1%85%A1%E1%86%B7%E1%84%8F%E1%85%A6%E1%84%8B%E1%85%A5%E1%84%91%E1%85%A9%E1%84%8B%E1%85%B5%E1%86%AB%E1%84%90%E1%85%B3_251201_jooyeon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**모델링**"
      ],
      "metadata": {
        "id": "yVA2hzFuVanz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import warnings\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "\n",
        "# Install catboost\n",
        "!pip install catboost\n",
        "\n",
        "# 모델 라이브러리\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, VotingClassifier, StackingClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhWkmGBOX9-s",
        "outputId": "44a73101-a4b0-4d7c-d4c2-34b0310cd541"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.12/dist-packages (1.2.8)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.2.5)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (9.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07bedeff",
        "outputId": "e74e1f86-4d4a-4595-cb5e-eb3d3c4cb6eb"
      },
      "source": [
        "# 데이터 분리 및 스케일링\n",
        "# 'smoking' 타겟은 이미 preprocess 함수에서 분리되어 `y` 변수에 저장되어 있습니다.\n",
        "\n",
        "# X_train과 y는 preprocess 함수에서 전처리된 데이터입니다.\n",
        "\n",
        "# X_test의 컬럼을 X_train의 컬럼과 일치시킵니다. (누락된 컬럼은 0으로 채움)\n",
        "train_cols = X_train.columns\n",
        "X_test_aligned = X_test.reindex(columns=train_cols, fill_value=0)\n",
        "\n",
        "# 선형 모델(Logistic, SVM)을 위해 스케일링\n",
        "scaler = StandardScaler()\n",
        "X_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
        "# Test셋은 Train셋의 Scaler로 변환 (정렬된 X_test 사용)\n",
        "test_final_scaled = pd.DataFrame(scaler.transform(X_test_aligned), columns=X_test_aligned.columns)\n",
        "\n",
        "# 검증셋 분리 (8:2)\n",
        "X_train_split, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"3. 데이터 준비 완료! (Train: {X_train_split.shape}, Val: {X_val.shape})\")\n",
        "print(\"=\"*60)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3. 데이터 준비 완료! (Train: (127404, 98), Val: (31852, 98))\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------------------------------------\n",
        "# [Step 1] 개별 모델 돌려보기 (Base Models)\n",
        "# --------------------------------------------------------------------------------\n",
        "print(\"[Step 1] 개별 모델 학습 및 평가 시작\")\n",
        "\n",
        "# NOTE: X_train, y, X_test는 preprocess에서 생성되었고,\n",
        "# X_train_split, X_val, y_train, y_val은 이전 셀에서 생성되었습니다.\n",
        "# 이 셀에서는 이미 생성된 X_train_split, X_val, y_train, y_val을 사용합니다.\n",
        "\n",
        "# XGBoost 호환성을 위해 컬럼 이름 정리\n",
        "# XGBoost는 피처 이름에 [, ] 또는 <와 같은 특수 문자를 허용하지 않음\n",
        "X_train_split.columns = X_train_split.columns.str.replace('[^A-Za-z0-9_]+', '', regex=True)\n",
        "X_val.columns = X_val.columns.str.replace('[^A-Za-z0-9_]+', '', regex=True)\n",
        "\n",
        "# SVM은 확률값(predict_proba)이 안 나오므로 CalibratedClassifierCV로 감싸야 함\n",
        "svm_base = LinearSVC(random_state=42)\n",
        "svm_calibrated = CalibratedClassifierCV(svm_base, method='sigmoid', cv=3)\n",
        "\n",
        "models = {\n",
        "    \"LGBM\": LGBMClassifier(n_estimators=1000, learning_rate=0.05, num_leaves=31, random_state=42, verbose=-1),\n",
        "    \"XGB\": XGBClassifier(n_estimators=1000, learning_rate=0.05, max_depth=6, random_state=42, n_jobs=-1),\n",
        "    \"CatBoost\": CatBoostClassifier(n_estimators=1000, learning_rate=0.05, depth=6, random_state=42, verbose=0),\n",
        "    \"RF\": RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1),\n",
        "    \"ExtraTrees\": ExtraTreesClassifier(n_estimators=200, random_state=42, n_jobs=-1),\n",
        "    \"Logistic\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "    \"SVM(Calibrated)\": svm_calibrated\n",
        "}\n",
        "\n",
        "fitted_models = {}\n",
        "results = {}\n",
        "\n",
        "print(f\"{'Model Name':<20} | {'Accuracy':<10} | {'AUC':<10} | {'Time'}\")\n",
        "print(\"-\" * 55)\n",
        "\n",
        "for name, model in models.items():\n",
        "    start = time.time()\n",
        "    model.fit(X_train_split, y_train)\n",
        "\n",
        "    pred = model.predict(X_val)\n",
        "    # SVM 등 일부 모델은 predict_proba 지원 여부 확인 필요 (Calibrated는 지원함)\n",
        "    if hasattr(model, \"predict_proba\"):\n",
        "        proba = model.predict_proba(X_val)[:, 1]\n",
        "    else:\n",
        "        proba = [0] * len(pred) # 예외처리\n",
        "\n",
        "    acc = accuracy_score(y_val, pred)\n",
        "    auc = roc_auc_score(y_val, proba)\n",
        "    elapsed = time.time() - start\n",
        "\n",
        "    print(f\"{name:<20} | {acc:.4f}     | {auc:.4f}     | {elapsed:.1f}s\")\n",
        "\n",
        "    fitted_models[name] = model\n",
        "    results[name] = acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IR-qVkjkZapA",
        "outputId": "5e6fae3a-512c-473b-a781-cd731d8df189"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 1] 개별 모델 학습 및 평가 시작\n",
            "Model Name           | Accuracy   | AUC        | Time\n",
            "-------------------------------------------------------\n",
            "LGBM                 | 0.7803     | 0.8628     | 33.8s\n",
            "XGB                  | 0.7794     | 0.8635     | 36.9s\n",
            "CatBoost             | 0.7793     | 0.8635     | 53.2s\n",
            "RF                   | 0.7701     | 0.8528     | 92.2s\n",
            "ExtraTrees           | 0.7669     | 0.8487     | 98.6s\n",
            "Logistic             | 0.7571     | 0.8408     | 4.6s\n",
            "SVM(Calibrated)      | 0.7572     | 0.8411     | 25.6s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # --------------------------------------------------------------------------------\n",
        "# # [Step 2] 가중치 있는 소프트 보팅 (Weighted Soft Voting)\n",
        "# # --------------------------------------------------------------------------------\n",
        "# print(\"\\n[Step 2] 가중치 보팅 (Weighted Soft Voting) 진행\")\n",
        "\n",
        "# # 1. Step 1에서 학습된 모델들 가져오기 (fitted_models 딕셔너리 활용)\n",
        "# # 성능이 좋았던 모델 Top 3(XGB, Cat, LGBM)에 가중치 높게\n",
        "# # 로지스틱이나 SVM은 성능은 낮지만 모델의 다양성(Diversity)을 위해 소량 섞음\n",
        "\n",
        "# # 예측 확률(Probability) 모으기\n",
        "# # fitted_models는 Step 1에서 이미 학습된 모델들이 들어있는 딕셔너리입니다.\n",
        "# preds = {\n",
        "#     \"LGBM\": fitted_models[\"LGBM\"].predict_proba(X_val)[:, 1],\n",
        "#     \"XGB\": fitted_models[\"XGB\"].predict_proba(X_val)[:, 1],\n",
        "#     \"CatBoost\": fitted_models[\"CatBoost\"].predict_proba(X_val)[:, 1],\n",
        "#     \"RF\": fitted_models[\"RF\"].predict_proba(X_val)[:, 1],\n",
        "#     \"Logistic\": fitted_models[\"Logistic\"].predict_proba(X_val)[:, 1],\n",
        "#     \"SVM\": fitted_models[\"SVM(Calibrated)\"].predict_proba(X_val)[:, 1]\n",
        "# }\n",
        "\n",
        "# # 2. 가중치 설정\n",
        "# # - 1군(0.862+): XGB, CatBoost, LGBM -> 가중치 4\n",
        "# # - 2군(0.85+): RF -> 가중치 2\n",
        "# # - 3군(0.83+): Logistic, SVM -> 가중치 1 (다양성 확보용)\n",
        "\n",
        "# weights = {\n",
        "#     \"LGBM\": 4,\n",
        "#     \"XGB\": 4,\n",
        "#     \"CatBoost\": 4,\n",
        "#     \"RF\": 2,\n",
        "#     \"Logistic\": 1,\n",
        "#     \"SVM\": 1\n",
        "# }\n",
        "\n",
        "# # 3. 가중 평균 계산 (Ensemble)\n",
        "# final_pred_proba = np.zeros(len(X_val))\n",
        "# total_weight = sum(weights.values())\n",
        "\n",
        "# for name, weight in weights.items():\n",
        "#     final_pred_proba += preds[name] * weight\n",
        "\n",
        "# final_pred_proba /= total_weight # 가중치 합으로 나누기\n",
        "\n",
        "# # 4. 성능 평가 (AUC & Accuracy)\n",
        "# voting_auc = roc_auc_score(y_val, final_pred_proba)\n",
        "# voting_acc = accuracy_score(y_val, np.where(final_pred_proba >= 0.5, 1, 0))\n",
        "\n",
        "# print(f\"[Voting 결과] 가중치 {list(weights.values())}\")\n",
        "# print(f\"   - ROC AUC : {voting_auc:.5f} (Step 1 최고점보다 상승했는지 확인)\")\n",
        "# print(f\"   - Accuracy: {voting_acc:.5f}\")\n"
      ],
      "metadata": {
        "id": "cRp4F7DtZ60I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------------------------------------\n",
        "# [Step 3] 스태킹 (Stacking)\n",
        "# --------------------------------------------------------------------------------\n",
        "print(\"\\n[Step 3] 스태킹 (Stacking)\")\n",
        "\n",
        "# Base로 쓸 모델 선정 (성능 좋은 것 + 성격 다른 것 조합)\n",
        "estimators = [\n",
        "    ('lgbm', models['LGBM']),\n",
        "    ('xgb', models['XGB']),\n",
        "    ('cat', models['CatBoost']),\n",
        "    ('rf', models['RF']),\n",
        "    ('et', models['ExtraTrees'])\n",
        "]\n",
        "\n",
        "# 메타 모델 (최종 결정자): 과적합 방지를 위해 보통 LogisticRegression을 많이 씀\n",
        "meta_model = LogisticRegression(random_state=42)\n",
        "\n",
        "stack_model = StackingClassifier(\n",
        "    estimators=estimators,\n",
        "    final_estimator=meta_model,\n",
        "    cv=2, # 내부 교차 검증 (시간 걸리면 줄이세요)\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "stack_model.fit(X_train_split, y_train)\n",
        "stack_pred = stack_model.predict(X_val)\n",
        "stack_acc = accuracy_score(y_val, stack_pred)\n",
        "\n",
        "print(f\"Stacking Accuracy = {stack_acc:.4f}\")"
      ],
      "metadata": {
        "id": "8_HSDKd8c99a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}